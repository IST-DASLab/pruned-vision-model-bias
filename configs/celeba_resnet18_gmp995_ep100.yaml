# Imagenet + RESNET50 with this config
# use the hyperparameters from here: https://github.com/adityakusupati/STR/blob/master/configs/largescale/resnet50-gmp.yaml

pruners:
  pruner_1:
    class: UnstructuredMagnitudePruner
    epochs: [10, 10, 81]
    initial_sparsity: 0.05
    target_sparsity: 0.995
    weight_only: True
    modules: [conv1, layer1.0.conv1, layer1.0.conv2, layer1.1.conv1, layer1.1.conv2,
              layer2.0.conv1, layer2.0.conv2, layer2.0.downsample.0, layer2.1.conv1, layer2.1.conv2,
              layer3.0.conv1, layer3.0.conv2, layer3.0.downsample.0, layer3.1.conv1, layer3.1.conv2,
              layer4.0.conv1, layer4.0.conv2, layer4.0.downsample.0, layer4.1.conv1, layer4.1.conv2, fc]
    keep_pruned: False
  


trainers:
  # use this trainer name unless you want KD or other custom thing
  default_trainer:
    optimizer:
      class: SGD
      lr: 0.256
      momentum: 0.875
      weight_decay: 0.00003051757813

    lr_scheduler:
      class: CosineLR
      warmup_length: 5
      end_epoch: 100
      epochs: [0, 1, 100]

