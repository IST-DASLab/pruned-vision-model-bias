# Imagenet + MobileNetV1 with this config
# use the hyperparameters from here: https://github.com/adityakusupati/STR/blob/master/configs/largescale/mobilenetv1-dense.yaml

pruners:
  pruner_1:
    class: UnstructuredMagnitudePruner
    epochs: [1, 4, 60]
    initial_sparsity: 0.05
    target_sparsity: 0.98
    weight_only: True
    modules: [model.0.0, model.1.0, model.1.3, model.2.0, model.2.3, model.3.0, model.3.3, model.4.0, model.4.3, 
              model.5.0, model.5.3, model.6.0, model.6.3, model.7.0, model.7.3, model.8.0, model.8.3, model.9.0,
              model.9.3, model.10.0, model.10.3, model.11.0, model.11.3, model.12.0, model.12.3, model.13.0,
              model.13.3, fc]
    keep_pruned: False


trainers:
  # use this trainer name unless you want KD or other custom thing
  default_trainer:
    optimizer:
      class: Adam
      lr: 0.0001

    lr_scheduler:
      class: MultiStepLR
      milestones: [100]
      gamma: 0.1
      epochs: [0, 1, 100]
